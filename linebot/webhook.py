from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.models import MessageEvent, TextMessage, TextSendMessage
from dotenv import load_dotenv
import sys
import os
import openai
from collections import defaultdict
from linebot.models import FlexSendMessage
from linebot.models import QuickReply, QuickReplyButton, MessageAction
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))


from eeg import process
from gpt_api.response import build_prompt, ask_gpt
from style_selector import make_style_flex
from persona_prompt_map import persona_map

def generate_eeg_flex_message(status_dict):
    # å°‡è¼¸å…¥çš„ key çµ±ä¸€è½‰æˆæ¨™æº– label
    label_mapping = {
        "relax": "Relax",
        "concentrating": "Focus",
        "stress": "Stress",
        "memory": "Memory"
    }

    # ç‹€æ…‹å°æ‡‰é¡è‰²ï¼ˆéœ€èˆ‡ label å®Œå…¨åŒ¹é…ï¼‰
    color_map = {
        "Relax": "#5CADAD",   # é’ç¶ è‰²
        "Focus": "#0072E3",   # ç´«è‰²
        "Stress": "#FF6B6E",  # ç´…è‰²
        "Memory": "#FF8040"   # ç¶ è‰²
    }

    # ç‹€æ…‹å°æ‡‰çŸ­å¥
    description_map = {
        "Relax": "èº«å¿ƒæ”¾é¬†ä¸­",
        "Focus": "å°ˆæ³¨åŠ›é›†ä¸­",
        "Stress": "å£“åŠ›å±±å¤§ä¸­",
        "Memory": "åŠªåŠ›è¨˜æ†¶ä¸­"
    }

    # å»ºç«‹å–®ä¸€ bubble
    def make_bubble(label, percent_float, color, description):
        percent_display = round(percent_float * 100, 1)
        percent_str = f"{percent_display}%"
        width_str = f"{percent_display}%"

        return {
            "type": "bubble",
            "size": "nano",
            "header": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {
                        "type": "text",
                        "text": label,
                        "color": "#ffffff",
                        "align": "start",
                        "size": "md",
                        "gravity": "center"
                    },
                    {
                        "type": "text",
                        "text": percent_str,
                        "color": "#ffffff",
                        "align": "start",
                        "size": "xs",
                        "gravity": "center",
                        "margin": "lg"
                    },
                    {
                        "type": "box",
                        "layout": "vertical",
                        "contents": [
                            {
                                "type": "box",
                                "layout": "vertical",
                                "contents": [{"type": "filler"}],
                                "width": width_str,
                                "backgroundColor": "#FFFFFF",
                                "height": "6px"
                            }
                        ],
                        "backgroundColor": "#3A3A3A",
                        "height": "6px",
                        "margin": "sm"
                    }
                ],
                "backgroundColor": color,
                "paddingTop": "19px",
                "paddingAll": "12px",
                "paddingBottom": "16px"
            },
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {
                        "type": "box",
                        "layout": "horizontal",
                        "contents": [
                            {
                                "type": "text",
                                "text": description,
                                "color": "#8C8C8C",
                                "size": "sm",
                                "wrap": True
                            }
                        ],
                        "flex": 1
                    }
                ],
                "spacing": "md",
                "paddingAll": "12px"
            },
            "styles": {
                "footer": {
                    "separator": False
                }
            }
        }

    # çµ„åˆæ‰€æœ‰ bubble
    bubbles = []
    for raw_label, percent_float in status_dict.items():
        label = label_mapping.get(raw_label.lower(), raw_label.title())
        color = color_map.get(label, "#999999")
        desc = description_map.get(label, "Your current brain state")
        bubbles.append(make_bubble(label, percent_float, color, desc))

    return {
        "type": "carousel",
        "contents": bubbles
    }

# === åˆå§‹åŒ– ===
load_dotenv("../.env")
app = Flask(__name__)
line_bot_api = LineBotApi(os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
handler = WebhookHandler(os.getenv("LINE_CHANNEL_SECRET"))

# === å°è©±æ­·å²ç®¡ç† ===
conversation_history = defaultdict(list)
user_style = defaultdict(dict)  # è¨˜ä½æ¯ä½ä½¿ç”¨è€…çš„ä¸‰å±¤è¨­å®š
user_eeg_history = defaultdict(list)
MAX_TURNS = 4  # æœ€å¤šä¿ç•™ 5 è¼ªå°è©±

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)

    try:
        handler.handle(body, signature)
    except Exception as e:
        print(f"âš ï¸ Webhook éŒ¯èª¤ï¼š{e}")
        abort(400)
    return 'OK'


# === ç³»çµ± prompt å°æ‡‰ç”Ÿæˆ ===
def build_custom_prompt(style):
    desc = persona_map.get(style.get("persona"), "")
    return (
        "ä½ æ˜¯ä¸€ä½åªæœƒèªªç¹é«”ä¸­æ–‡çš„èŠå¤©å¤¥ä¼´ï¼Œè«‹ä¾ç…§ä»¥ä¸‹è§’è‰²é¢¨æ ¼å›æ‡‰ä½¿ç”¨è€…ï¼š"
        + desc +
        "å¦‚æœè¿‘å¹¾è¼ªçš„èŠå¤©å…§å®¹ä¸­æœ‰ã€Œæ”¶åˆ°ï¼æˆ‘æœƒå¾€æ›´...çš„æ–¹å‘æ”¹é€²ï¼ã€ï¼Œè«‹è¨˜å¾—ä»¥æ­¤æ–¹å‘ä¾†åšä¿®æ­£ä»¥ç¬¦åˆä½¿ç”¨è€…åå¥½"
        "\nåœ¨æ—¥å¸¸å°è©±ä¸­ï¼Œæ ¹æ“šä½¿ç”¨è€…çš„è¼¸å…¥èˆ‡æœ€è¿‘å¹¾è¼ªçš„èŠå¤©å…§å®¹ï¼Œçµ¦å‡ºå…·é«”ã€è‡ªç„¶ã€æœ‰å¹«åŠ©çš„å›æ‡‰ã€‚\nä¸è¦å¤ªåˆ¶å¼ï¼Œä¿æŒäººå‘³ï¼Œè¨Šæ¯ç›¡é‡åœ¨50å­—ï¼Œæœ€å¾Œè«‹ç¢ºèªæ‰€æœ‰å›æ‡‰éƒ½æ˜¯ç¹é«”å­—ï¼Œå›è¦†ä¸éœ€è¦ç”¨å¼•è™Ÿæ‹¬èµ·ä¾†"
    )

def make_feedback_quick_reply():
    return QuickReply(
        items=[
            QuickReplyButton(action=MessageAction(label="å¤ªé•·äº†ï¼Œè«‹ç²¾ç°¡ä¸€é»", text="å¤ªé•·äº†ï¼Œè«‹ç²¾ç°¡ä¸€é»")),
            QuickReplyButton(action=MessageAction(label="å¤ªæ¨¡ç³Šäº†ï¼Œè«‹å…·é«”ä¸€é»", text="å¤ªæ¨¡ç³Šäº†ï¼Œè«‹å…·é«”ä¸€é»")),
            QuickReplyButton(action=MessageAction(label="å¤ªå®˜è…”äº†ï¼Œè«‹å¹½é»˜ä¸€é»", text="å¤ªå®˜è…”äº†ï¼Œè«‹å¹½é»˜ä¸€é»")),
        ]
    )

# === è™•ç†ä½¿ç”¨è€…è¨Šæ¯ ===
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_id = event.source.user_id
    text = event.message.text.strip()
    history = user_eeg_history.get(user_id, [])

    if text == "å‚³é€EEG":
        try:
            # eeg_path = "../data/data_stress.txt"  # å¯æ”¹ç‚ºè‡ªå‹•è®€æœ€æ–° EEG
            eeg_path = "/mnt/c/Users/é™³éƒç²/Desktop/BIOPAC/data/data.txt"
            eeg_state = process.predict_prob(eeg_path)
            
            # åŠ å…¥ EEG æ­·å²ï¼ˆæœ€å¤š 3 ç­†ï¼‰
            user_eeg_history[user_id].append(eeg_state)
            if len(user_eeg_history[user_id]) > 3:
                user_eeg_history[user_id] = user_eeg_history[user_id][-3:]

            # åŠ å…¥è‡ªå®šç¾©é¢¨æ ¼ï¼Œè‹¥ç„¡å‰‡ç”¨é è¨­
            style = user_style.get(user_id, {
                "intent": "intent_relax",
                "tone": "tone_soft",
                "persona": "persona_parent"
            })
            
            prompt = build_prompt(eeg_state, history=history)
            print(f"ğŸ§  EEG åˆ†é¡æ©Ÿç‡ï¼š{eeg_state}")
            reply = ask_gpt(prompt, style)    
            # å»ºç«‹ EEG ç‹€æ…‹æ–‡å­—æè¿°
            percentages = [f"{prob:.0%}" for prob in eeg_state.values()]
            eeg_text = "ğŸ§  å„è…¦æ³¢åˆ†é¡æ©Ÿç‡ï¼š" + f"({', '.join(percentages)})"    

            # å»ºç«‹ Flex Message
            flex_json = generate_eeg_flex_message(eeg_state)
            flex_msg = FlexSendMessage(alt_text="ğŸ§  è…¦æ³¢ç‹€æ…‹åˆ†æ", contents=flex_json)

            # line_bot_api.push_message(user_id, TextSendMessage(text=reply))
            # line_bot_api.push_message(user_id, flex_msg)
            line_bot_api.reply_message(
                event.reply_token,
                messages=[
                    TextSendMessage(text=reply),
                    TextSendMessage(text=eeg_text),
                    flex_msg
                ]
            )
        except Exception as e:
            # line_bot_api.push_message(user_id, TextSendMessage(text=f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}"))
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text=f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            )

    elif text == "å»ºç«‹å°ˆå±¬è§’è‰²":
        user_style[user_id] = {}  
        # line_bot_api.push_message(user_id, make_style_flex("persona_only"))
        line_bot_api.reply_message(event.reply_token, make_style_flex("persona_only"))

    elif text.startswith("persona_"):
        user_style[user_id]["persona"] = text
        conversation_history[user_id] = []  # ğŸ” æ¸…ç©ºæ­·å²å°è©±
        # line_bot_api.push_message(user_id, TextSendMessage(text="âœ… å·²å„²å­˜ä½ çš„å°è©±é¢¨æ ¼ï¼Œå¾ç¾åœ¨é–‹å§‹æˆ‘æœƒç…§é€™æ¨£å›è¦†ä½ ï¼"))
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âœ… å·²å„²å­˜ä½ çš„å°è©±é¢¨æ ¼ï¼Œå¾ç¾åœ¨é–‹å§‹æˆ‘æœƒç…§é€™æ¨£å›è¦†ä½ ï¼"))


    else:
        conversation_history[user_id].append({"role": "user", "content": text})
        # ä¿ç•™æœ€è¿‘ MAX_TURNS è¼ªå°è©±
        if len(conversation_history[user_id]) > MAX_TURNS * 2:
            conversation_history[user_id] = conversation_history[user_id][-MAX_TURNS * 2:]

        style = user_style.get(user_id, {
            "persona": "persona_general"
        })

        system_prompt = build_custom_prompt(style)

        try:
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[{"role": "system", "content": system_prompt}] + conversation_history[user_id]
            )
            reply = response["choices"][0]["message"]["content"]
            conversation_history[user_id].append({"role": "assistant", "content": reply})
            # line_bot_api.push_message(user_id, TextSendMessage(text=reply))
            # âœ… ä½¿ç”¨ reply_message å›å‚³
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(
                    text=reply,
                    quick_reply=make_feedback_quick_reply()
                )
            )
        except Exception as e:
            # line_bot_api.push_message(user_id, TextSendMessage(text=f"âš ï¸ GPT å›æ‡‰éŒ¯èª¤ï¼š{e}"))
            line_bot_api.reply_message(
                event.reply_token,
                TextSendMessage(text=f"âš ï¸ GPT å›æ‡‰éŒ¯èª¤ï¼š{e}")
            )



if __name__ == "__main__":
    app.run(port=5000)

