import os
import openai
from dotenv import load_dotenv
from gpt.persona_map import persona_map

load_dotenv("../.env")
openai.api_key = os.getenv("OPENAI_API_KEY")

def build_prompt(eeg_state, history=None):
    """
    æ ¹æ“š EEG åˆ†é¡æ©Ÿç‡è¼¸å‡ºé©åˆ GPT çš„æç¤ºèªå¥ï¼Œè®“ GPT ä»¥å¹´è¼•å¹½é»˜åˆå°ˆæ¥­çš„æ–¹å¼å›æ‡‰ã€‚
    """
    # ä¸­æ–‡è½‰æ›å°æ‡‰
    label_map = {
        "relax": "æ”¾é¬†",
        "concentrating": "å°ˆæ³¨",
        "stress": "å£“åŠ›",
        "memory": "è¨˜æ†¶"
    }

    # å¼·åŒ–ä¸»å°ç‹€æ…‹çš„å€åˆ†ï¼ˆæ‹‰å¤§æ¯”ä¾‹å·®ç•°ï¼‰
    amplified = {k: v ** 1.5 for k, v in eeg_state.items()}
    total = sum(amplified.values())
    normed = {k: v / total for k, v in amplified.items()}

    # å–ä¸»å°ç‹€æ…‹
    sorted_state = sorted(normed.items(), key=lambda x: x[1], reverse=True)
    dominant_key, dominant_val = sorted_state[0]
    dominant_label = label_map[dominant_key]
    # ä½† percent_text æ”¹ç‚ºåŸå§‹å€¼
    true_percent = eeg_state[dominant_key]
    percent_text = f"{round(true_percent * 100, 1)}%"

    # å®Œæ•´ç‹€æ…‹æè¿°
    state_str = "ï¼Œ".join([f"{label_map[k]} {round(v * 100, 1)}%" for k, v in sorted_state])
    
    # åŠ å…¥æ­·å²ç´€éŒ„
    history_summary = ""
    if history and len(history) > 1:
        recent = []
        for hist in history[-3:]:
            dominant = max(hist.items(), key=lambda x: x[1])[0]
            recent.append(label_map.get(dominant, dominant))
        history_summary = (
            f"\nï¼ˆæ­·å²è³‡æ–™ï¼š{' â†’ '.join(recent)}ï¼‰"
        )

    # çµæ§‹åŒ– prompt
    prompt = (
        f"è«‹ä¾æ“šä»¥ä¸‹è…¦æ³¢ç‹€æ…‹ï¼š{state_str}ï¼Œå…¶ä¸­ä¸»è¦ç‹€æ…‹ç‚ºã€Œ{dominant_label}ï¼ˆ{percent_text}ï¼‰ã€ã€‚"
        + history_summary +
        f"è«‹ç”Ÿæˆä¸€æ®µåŒ…å«ä»¥ä¸‹æ ¼å¼çš„æ–‡å­—ï¼š\n\n"
        f"ğŸ¯ ç›®å‰ç‹€æ…‹ï¼š{dominant_label}ï¼ˆ{percent_text}ï¼‰\n\n"
        f"ğŸ“ˆ ç‹€æ…‹è®ŠåŒ–:é–±è®€æ­·å²è³‡æ–™ï¼Œç›´æ¥ç”¨ã€Œè¨˜æ†¶ â†’ æ”¾é¬† â†’ è¨˜æ†¶ã€é¡ä¼¼é€™æ¨£çš„æ–¹å¼å‘ˆç¾ç‹€æ…‹è®ŠåŒ–ï¼Œæ²’æœ‰æ­·å²è³‡æ–™æ™‚å‰‡ä¸ç”Ÿæˆç‹€æ…‹è®ŠåŒ–é€™ä¸€è¡Œ\n\n"
        f"ğŸ§  åˆ†æï¼šä¸€å¥è©±èªªæ˜é€™ç¨®ç‹€æ…‹é€šå¸¸æœƒæœ‰ä»€éº¼æ„Ÿå—æˆ–ç¾è±¡ï¼ˆç”¨å¹´è¼•èªæ°£ã€100å­—ä»¥å…§ï¼‰\n\n"
        f"ğŸŒ± å»ºè­°èˆ‡é¼“å‹µï¼šä¸€æ®µå»ºè­°æˆ–å®‰æ…°çš„è©±ï¼Œç¬¦åˆè§’è‰²è¨­å®š(150å­—ä»¥å…§)\n\n"
    )
    print("=== æœ€çµ‚ç”Ÿæˆçš„ Prompt ===")
    print(prompt)

    return prompt

# def ask_gpt(prompt, style=None):
#     try:
#         response = openai.ChatCompletion.create(
#             model="gpt-4",
#             messages=[
#                 {
#                     "role": "system",
#                     "content": (
#                         "ä½ æ˜¯ä¸€ä½æœƒèªªç¹é«”ä¸­æ–‡ã€æ‡‚è…¦æ³¢ã€æ‡‚é›»æ©Ÿç³»å¤§å­¸ç”Ÿçš„é™ªèŠå¤¥ä¼´ã€‚"
#                         "ä½ å¾ˆæœƒå®‰æ…°ã€ç†è§£åˆ¥äººå¿ƒç†ç‹€æ…‹ï¼Œç”¨è©è‡ªç„¶ä¸åšä½œï¼Œæœ‰æ™‚å€™å¯ä»¥è¼•é¬†å¹½é»˜ï¼Œ"
#                         "ä½†é‡é»æ˜¯è®“å°æ–¹è¦ºå¾—è¢«ç†è§£ã€æœ‰å¹«åŠ©ã€‚è«‹æ ¹æ“š prompt åˆ†æå‡ºå°æ–¹çš„ä¸»å°ç‹€æ…‹ä¸¦çµ¦å‡ºå°ˆæ¥­ä½†è²¼è¿‘ç”Ÿæ´»çš„å»ºè­°ã€‚"
#                     )
#                 },
#                 {"role": "user", "content": prompt}
#             ]
#         )
#         return response['choices'][0]['message']['content']
#     except Exception as e:
#         return f"âš ï¸ GPT å‘¼å«å¤±æ•—ï¼š{e}"

def ask_gpt(prompt, style=None):
    try:
        # é è¨­çš„è§’è‰²æè¿°
        base_system_prompt = (
            "ä½ æ˜¯ä¸€ä½æœƒèªªç¹é«”ä¸­æ–‡ã€æ‡‚è…¦æ³¢ã€ç†è§£åˆ¥äººå¿ƒç†ç‹€æ…‹ã€ç”¨è©è‡ªç„¶ä¸åšä½œã€‚"
            "ä½ æ“…é•·å®‰æ…°ã€é¼“å‹µã€æˆ–é™ªä¼´é›»æ©Ÿç³»å¤§å­¸ç”Ÿï¼Œå›æ‡‰é¢¨æ ¼è¦æœ‰æº«åº¦ã€è‡ªç„¶ï¼Œå¿…è¦æ™‚å¯ä»¥å¹´è¼•å¹½é»˜ã€‚"
        )

        # æ ¹æ“šè§’è‰²é¢¨æ ¼æ•´åˆé¢¨æ ¼æè¿°
        persona_desc = ""
        if style and "persona" in style:
            persona_key = style.get("persona")
            persona_desc = persona_map.get(persona_key, "")

        full_system_prompt = base_system_prompt + "\n\n" + persona_desc

        # å»ºç«‹å°è©±
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": full_system_prompt},
                {"role": "user", "content": prompt}
            ]
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        return f"âš ï¸ GPT å‘¼å«å¤±æ•—ï¼š{e}"

# def build_prompt(eeg_state):
#     """
#     æ ¹æ“š EEG åˆ†é¡æ©Ÿç‡è¼¸å‡ºé©åˆ GPT çš„æç¤ºèªå¥ã€‚
#     eeg_state: Dictï¼Œä¾‹å¦‚ {'relax': 0.2, 'concentrating': 0.3, 'stress': 0.4, 'memory': 0.1}
#     """
#     sorted_state = sorted(eeg_state.items(), key=lambda x: x[1], reverse=True)
#     state_text = "ï¼Œ".join([f"{k} {int(v * 100)}%" for k, v in sorted_state])
#     prompt = f"ä½ æ˜¯ä¸€å€‹æº«æŸ”çš„èŠå¤©å¤¥ä¼´ï¼Œå°æ–¹çš„è…¦æ³¢ç‹€æ…‹å¦‚ä¸‹ï¼š{state_text}ï¼Œè«‹ç”¨100å­—é¼“å‹µä»–ã€‚"
#     return prompt

# è¼‰å…¥ API é‡‘é‘°
# def ask_gpt(prompt):
#     """
#     å‘¼å« OpenAI GPT APIï¼Œè¼¸å…¥ promptï¼Œå›å‚³å›æ‡‰æ–‡å­—ã€‚
#     """
#     try:
#         response = openai.ChatCompletion.create(
#             model="gpt-4",
#             messages=[
#                 {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹èƒ½æ ¹æ“šè…¦æ³¢æ•¸æ“šå®‰æ…°æˆ–é¼“å‹µç”¨æˆ¶çš„èŠå¤©æ©Ÿå™¨äººã€‚"},
#                 {"role": "user", "content": prompt}
#             ]
#         )
#         return response['choices'][0]['message']['content']
#     except Exception as e:
#         return f"âš ï¸ GPT å‘¼å«å¤±æ•—ï¼š{e}"

# æ¸¬è©¦ç”¨
# eeg_state = {'relax': 0.2, 'concentrating': 0.3, 'stress': 0.4, 'memory': 0.1}
# prompt = build_prompt(eeg_state)
# reply = ask_gpt(prompt)
# print(reply)